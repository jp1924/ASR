{
    // Use IntelliSense to learn about possible attributes.
    // Hover to view descriptions of existing attributes.
    // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387
    "version": "0.2.0",
    "configurations": [
        {
            "name": "Python 디버거: 현재 파일",
            "type": "debugpy",
            "request": "launch",
            "program": "${file}",
            "console": "integratedTerminal",
            "justMyCode": false
        },
        {
            "name": "Wav2Vec2 FineTune-Single",
            "type": "debugpy",
            "request": "launch",
            "program": "/root/wav2vec2_pretrain.py",
            "console": "integratedTerminal",
            "justMyCode": false,
            "env": {
                "CUDA_VISIBLE_DEVICE": "0",
                "TORCHDYNAMO_DISABLE": "1",
                "WANDB_DISABLED": "true",
            },
            "args": []
        },
        {
            "name": "Wav2Vec2 FineTune-DDP",
            "type": "debugpy",
            "request": "launch",
            "module": "torch.distributed.launch",
            "console": "integratedTerminal",
            "env": {
                "CUDA_VISIBLE_DEVICE": "0,1,2,3",
                "TORCHDYNAMO_DISABLE": "1",
                "NCCL_P2P_DISABLE": "1",
                "NCCL_IB_DISABLE": "1",
                "WANDB_DISABLED": "true",
                "OMP_NUM_THREADS": "4",
            },
            "justMyCode": false,
            "args": []
        },
        {
            "name": "Wav2Vec2 FineTune-DeepSpeed",
            "type": "debugpy",
            "request": "launch",
            "module": "deepspeed.launcher.runner",
            "console": "integratedTerminal",
            "env": {
                "CUDA_VISIBLE_DEVICE": "0,1,2,3",
                "TORCHDYNAMO_DISABLE": "1",
                "NCCL_P2P_DISABLE": "1",
                "NCCL_IB_DISABLE": "1",
                "WANDB_DISABLED": "true",
                "OMP_NUM_THREADS": "4",
            },
            "justMyCode": false,
            "args": []
        },
        {
            "name": "Wav2Vec2 Pretrain-Single",
            "type": "debugpy",
            "request": "launch",
            "program": "/root/workspace/wav2vec2_pretrain.py",
            "console": "integratedTerminal",
            "justMyCode": false,
            "env": {
                "CUDA_VISIBLE_DEVICE": "0",
                "WANDB_PROJECT": "Wav2Vec2",
                "WANDB_RUN_GROUP": "test",
                "WANDB_DISABLE_CODE": "true",
                "WANDB_ENTITY": "jp_42maru",
                "TORCHDYNAMO_DISABLE": "1",
                "WANDB_DISABLED": "false",
            },
            "args": [
                "--output_dir=/root/output_dir",
                "--run_name=debug",
                "--model_name_or_path=/root/model",
                "--preprocessing_num_workers=20",
                "--per_device_train_batch_size=18",
                "--overwrite_cache=false",
                "--cache_dir=false",
                "--max_steps=2",
                "--do_train=true",
                "--do_eval=true",
                "--do_predict=true",
                "--report_to=none",
                "--learning_rate=5e-4",
                "--warmup_ratio=0.08",
                "--weight_decay=0.01",
                "--eval_strategy=steps",
                "--eval_steps=1",
                "--save_strategy=steps",
                "--logging_strategy=steps",
                "--fp16=true",
                "--dataset_repo_ls",
                "jp1924/KsponSpeech",
                // "jp1924/KrespSpeech",
                // "jp1924/KoreaSpeech",
                // "jp1924/KconfSpeech",
                // "jp1924/MeetingSpeech",
                // "jp1924/BroadcastSpeech",
                "--train_dataset_prefix=train",
                "--valid_dataset_prefix",
                "validation",
                "dev",
                "--test_dataset_prefix",
                "eval",
                "--cache_file_name=preprocessor.arrow",
                "--cache_dir=/root/.cache/.preprocessor_cache_dir",
            ]
        },
        {
            "name": "Wav2Vec2 Pretrain-DDP",
            "type": "debugpy",
            "request": "launch",
            "module": "torch.distributed.launch",
            "console": "integratedTerminal",
            "env": {
                "CUDA_VISIBLE_DEVICE": "0,1,2,3,4,5,6,7",
                "TORCHDYNAMO_DISABLE": "1",
                "NCCL_P2P_DISABLE": "1",
                "NCCL_IB_DISABLE": "1",
                "WANDB_DISABLED": "false",
                "OMP_NUM_THREADS": "4",
            },
            "justMyCode": false,
            "args": [
                "--nproc_per_node=1",
                "--master-port=8135",
                "/root/workspace/wav2vec2_pretrain.py",
                "--output_dir=/root/output_dir",
                // "--max_steps=2",
                "--run_name=debug",
                "--model_name_or_path=/root/output_dir/checkpoint-50000",
                "--preprocessing_num_workers=20",
                "--per_device_train_batch_size=4",
                "--gradient_accumulation_steps=1",
                "--per_device_eval_batch_size=20",
                "--overwrite_cache=false",
                "--cache_dir=false",
                "--seed=42",
                "--do_train=true",
                "--do_eval=true",
                "--do_predict=true",
                "--report_to=wandb",
                "--learning_rate=5e-4",
                "--warmup_ratio=0.08",
                "--weight_decay=0.01",
                "--eval_strategy=steps",
                "--eval_steps=1",
                "--save_strategy=no",
                "--logging_strategy=steps",
                "--logging_steps=1",
                "--fp16=false",
                "--dataset_repo_ls",
                "jp1924/KsponSpeech",
                "jp1924/KrespSpeech",
                "jp1924/KoreaSpeech",
                "jp1924/KconfSpeech",
                // "jp1924/MeetingSpeech",
                // "jp1924/BroadcastSpeech",
                "--train_dataset_prefix=train",
                "--valid_dataset_prefix",
                "validation",
                "dev",
                "--test_dataset_prefix",
                "eval_clean",
                "eval_other",
                "--cache_file_name=preprocessor.arrow",
                "--cache_dir=/root/.cache/.preprocessor_cache_dir",
                "--torch_compile=true",
            ]
        },
        {
            "name": "Wav2Vec2 Pretrain-DeepSpeed",
            "type": "debugpy",
            "request": "launch",
            "module": "deepspeed.launcher.runner",
            "console": "integratedTerminal",
            "env": {
                "CUDA_VISIBLE_DEVICE": "0,1,2,3",
                "TORCHDYNAMO_DISABLE": "1",
                "NCCL_P2P_DISABLE": "1",
                "NCCL_IB_DISABLE": "1",
                "OMP_NUM_THREADS": "4",
                "HF_TOKEN": "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",
            },
            "justMyCode": false,
            "args": [
                "--include=localhost:0,1,2,3",
                "/root/workspace/wav2vec2_pretrain.py",
                "--output_dir=/root/output_dir/wav2vec2/pretraining",
                "--run_name=debug",
                "--model_name_or_path=jp1924/KoWav2Vec2Base",
                "--overwrite_cache=false",
                "--per_device_train_batch_size=25",
                "--min_duration_in_seconds=400",
                "--max_duration_in_seconds=160000",
                "--preprocessing_num_workers=10",
                "--cache_dir=/root/.cache/.[KoWav2Vec2Base]pretraining_preprocess",
                "--cache_file_name=preprocessor.arrow",
                "--seed=42",
                "--do_train=true",
                "--do_eval=false",
                "--do_predict=false",
                "--report_to=none",
                "--learning_rate=5e-4",
                "--warmup_ratio=0.3",
                "--weight_decay=0.001",
                "--eval_strategy=no",
                "--save_strategy=no",
                "--logging_strategy=steps",
                "--logging_steps=1",
                "--fp16=true",
                "--dataset_repo_ls",
                "jp1924/KsponSpeech",
                "--train_dataset_prefix=train",
                "--valid_dataset_prefix",
                "validation",
                "dev",
                "--test_dataset_prefix",
                "eval_clean",
                "eval_other",
                "--do_packing=1",
                "--deepspeed=/root/workspace/ds_config/ZeRO_2_act_check.json"
            ]
        },
        {
            "name": "TNT SFT-DDP",
            "type": "debugpy",
            "cwd": "/root/workspace/sub_project/txt_num_txt/",
            "request": "launch",
            "module": "torch.distributed.launch",
            "console": "integratedTerminal",
            "env": {
                "CUDA_VISIBLE_DEVICE": "0,1",
                "TORCHDYNAMO_DISABLE": "1",
                "NCCL_P2P_DISABLE": "1",
                "NCCL_IB_DISABLE": "1",
                "WANDB_DISABLED": "true",
                "OMP_NUM_THREADS": "4",
            },
            "justMyCode": false,
            "args": [
                "/root/workspace//sub_project/txt_num_txt/main.py",
                "--output_dir=/root/output_dir",
                "--run_name=axolotl_test",
                "--model_name_or_path=/root/workspace/misc/llm_model",
                "--preprocessing_num_workers=10",
                "--per_device_train_batch_size=10",
                "--gradient_accumulation_steps=2",
                "--per_device_eval_batch_size=2",
                "--seed=42",
                "--do_train=true",
                "--do_eval=false",
                "--do_predict=true",
                "--report_to=none",
                "--learning_rate=5e-4",
                "--warmup_ratio=0.4",
                "--weight_decay=0.01",
                "--eval_strategy=no",
                "--save_strategy=no",
                "--logging_strategy=steps",
                "--logging_steps=1",
                "--bf16=true",
                "--dataset_repo_ls=jp1924/TNT_inst",
                "--gradient_checkpointing=true",
                "--torch_compile=true",
                "--fsdp=full_shard auto_wrap",
                "--fsdp_transformer_layer_cls_to_wrap=LlamaDecoderLayer",
            ]
        },
    ]
}